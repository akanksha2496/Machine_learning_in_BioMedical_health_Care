{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CMD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd4QPX9jtET_",
        "outputId": "66932d57-13d5-4375-a6a8-4bfff8e80428"
      },
      "source": [
        "!python3 /content/group_9_priyankaboral_mt19127.py \"kaggle_train.csv\" \"kaggle_test.csv\" \"output.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential model with dense layer\n",
            "2020-12-07 11:03:27.597854: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-12-07 11:03:28.916146: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-12-07 11:03:28.928082: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-12-07 11:03:28.928135: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (abc219ada81d): /proc/driver/nvidia/version does not exist\n",
            "2020-12-07 11:03:28.934555: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2250000000 Hz\n",
            "2020-12-07 11:03:28.934832: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1dc2bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-12-07 11:03:28.934863: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1784.28040, saving model to .mdl_wts.hdf5\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1784.28040\n",
            "\n",
            "Epoch 00003: val_loss improved from 1784.28040 to 878.73059, saving model to .mdl_wts.hdf5\n",
            "\n",
            "Epoch 00004: val_loss improved from 878.73059 to 778.75964, saving model to .mdl_wts.hdf5\n",
            "\n",
            "Epoch 00005: val_loss improved from 778.75964 to 716.10614, saving model to .mdl_wts.hdf5\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 716.10614\n",
            "\n",
            "Epoch 00060: val_loss improved from 716.10614 to 699.35645, saving model to .mdl_wts.hdf5\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 699.35645\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 699.35645\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 699.35645\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 699.35645\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 699.35645\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 699.35645\n",
            "\n",
            "Epoch 00067: val_loss improved from 699.35645 to 608.24982, saving model to .mdl_wts.hdf5\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 608.24982\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 608.24982\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 608.24982\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 608.24982\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 608.24982\n",
            "\n",
            "Epoch 00073: val_loss improved from 608.24982 to 604.66284, saving model to .mdl_wts.hdf5\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 604.66284\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 604.66284\n",
            "Accuracy: 55.10\n",
            "WARNING:tensorflow:From /content/group_9_priyankaboral_mt19127.py:68: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "MCC at Sequential:  0.09443843292997713\n",
            "Epoch 1/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 409.5404 - accuracy: 0.6000\n",
            "Epoch 00001: val_loss improved from 604.66284 to 410.85284, saving model to .mdl_wts.hdf5\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 329.2862 - accuracy: 0.8135 - val_loss: 410.8528 - val_accuracy: 0.6939\n",
            "Epoch 2/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 12.2749 - accuracy: 0.9000\n",
            "Epoch 00002: val_loss improved from 410.85284 to 384.34311, saving model to .mdl_wts.hdf5\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 249.5357 - accuracy: 0.7668 - val_loss: 384.3431 - val_accuracy: 0.8367\n",
            "Epoch 3/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 125.7449 - accuracy: 0.8000\n",
            "Epoch 00003: val_loss did not improve from 384.34311\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 171.7581 - accuracy: 0.7876 - val_loss: 388.2806 - val_accuracy: 0.7347\n",
            "Epoch 4/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 7.6942e-09 - accuracy: 1.0000\n",
            "Epoch 00004: val_loss improved from 384.34311 to 263.57193, saving model to .mdl_wts.hdf5\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 134.4113 - accuracy: 0.8549 - val_loss: 263.5719 - val_accuracy: 0.7755\n",
            "Epoch 5/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 23.7396 - accuracy: 0.7000\n",
            "Epoch 00005: val_loss improved from 263.57193 to 201.42752, saving model to .mdl_wts.hdf5\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 98.4786 - accuracy: 0.8342 - val_loss: 201.4275 - val_accuracy: 0.7959\n",
            "Epoch 6/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 7.3554 - accuracy: 0.9000\n",
            "Epoch 00006: val_loss did not improve from 201.42752\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 55.0911 - accuracy: 0.8808 - val_loss: 243.0491 - val_accuracy: 0.7551\n",
            "Epoch 7/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 31.2625 - accuracy: 0.9000\n",
            "Epoch 00007: val_loss did not improve from 201.42752\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 62.8095 - accuracy: 0.8705 - val_loss: 225.4105 - val_accuracy: 0.7959\n",
            "Epoch 8/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00008: val_loss improved from 201.42752 to 198.87643, saving model to .mdl_wts.hdf5\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 49.0402 - accuracy: 0.8705 - val_loss: 198.8764 - val_accuracy: 0.8163\n",
            "Epoch 9/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 80.1646 - accuracy: 0.9000\n",
            "Epoch 00009: val_loss did not improve from 198.87643\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 46.1229 - accuracy: 0.8912 - val_loss: 298.8339 - val_accuracy: 0.7347\n",
            "Epoch 10/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.6220 - accuracy: 0.9000\n",
            "Epoch 00010: val_loss improved from 198.87643 to 152.63518, saving model to .mdl_wts.hdf5\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 41.0266 - accuracy: 0.9223 - val_loss: 152.6352 - val_accuracy: 0.8571\n",
            "Epoch 11/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 122.4660 - accuracy: 0.8000\n",
            "Epoch 00011: val_loss did not improve from 152.63518\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 30.4084 - accuracy: 0.8964 - val_loss: 211.0554 - val_accuracy: 0.8367\n",
            "Epoch 12/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 8.1697e-21 - accuracy: 1.0000\n",
            "Epoch 00012: val_loss did not improve from 152.63518\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 130.7682 - accuracy: 0.8756 - val_loss: 232.8534 - val_accuracy: 0.7755\n",
            "Epoch 13/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00013: val_loss did not improve from 152.63518\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 42.7693 - accuracy: 0.9119 - val_loss: 182.0071 - val_accuracy: 0.8163\n",
            "Epoch 14/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00014: val_loss did not improve from 152.63518\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 28.1716 - accuracy: 0.9482 - val_loss: 214.9917 - val_accuracy: 0.8163\n",
            "Epoch 15/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 6.5685 - accuracy: 0.9000\n",
            "Epoch 00015: val_loss did not improve from 152.63518\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 31.1540 - accuracy: 0.9067 - val_loss: 160.9799 - val_accuracy: 0.8163\n",
            "Epoch 16/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 11.4656 - accuracy: 0.9000\n",
            "Epoch 00016: val_loss improved from 152.63518 to 146.81699, saving model to .mdl_wts.hdf5\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 6.8509 - accuracy: 0.9534 - val_loss: 146.8170 - val_accuracy: 0.8367\n",
            "Epoch 17/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 3.9305e-24 - accuracy: 1.0000\n",
            "Epoch 00017: val_loss improved from 146.81699 to 128.80121, saving model to .mdl_wts.hdf5\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 10.3616 - accuracy: 0.9482 - val_loss: 128.8012 - val_accuracy: 0.8571\n",
            "Epoch 18/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 8.3531e-09 - accuracy: 1.0000\n",
            "Epoch 00018: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 38.1892 - accuracy: 0.9430 - val_loss: 191.2441 - val_accuracy: 0.7959\n",
            "Epoch 19/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 7.9079 - accuracy: 0.9000\n",
            "Epoch 00019: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 48.8576 - accuracy: 0.9378 - val_loss: 163.5864 - val_accuracy: 0.7959\n",
            "Epoch 20/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 4.5131 - accuracy: 0.9000\n",
            "Epoch 00020: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 148.5923 - accuracy: 0.8860 - val_loss: 293.8229 - val_accuracy: 0.7347\n",
            "Epoch 21/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 34.6320 - accuracy: 0.9000\n",
            "Epoch 00021: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 59.5447 - accuracy: 0.9171 - val_loss: 207.5182 - val_accuracy: 0.7347\n",
            "Epoch 22/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00022: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 13.4900 - accuracy: 0.9378 - val_loss: 173.2601 - val_accuracy: 0.8367\n",
            "Epoch 23/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 20.4656 - accuracy: 0.7000\n",
            "Epoch 00023: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 10.3773 - accuracy: 0.9585 - val_loss: 149.6231 - val_accuracy: 0.8367\n",
            "Epoch 24/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00024: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 10.6127 - accuracy: 0.9482 - val_loss: 172.0071 - val_accuracy: 0.7755\n",
            "Epoch 25/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 1.2323 - accuracy: 0.8000\n",
            "Epoch 00025: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 25.9648 - accuracy: 0.9637 - val_loss: 164.0671 - val_accuracy: 0.7959\n",
            "Epoch 26/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 1.9295e-36 - accuracy: 1.0000\n",
            "Epoch 00026: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7258 - accuracy: 0.9845 - val_loss: 160.9114 - val_accuracy: 0.8163\n",
            "Epoch 27/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00027: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 4.2432 - accuracy: 0.9741 - val_loss: 144.1421 - val_accuracy: 0.8367\n",
            "Epoch 28/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00028: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 38.9999 - accuracy: 0.9275 - val_loss: 172.2098 - val_accuracy: 0.7959\n",
            "Epoch 29/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00029: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 35.3610 - accuracy: 0.9016 - val_loss: 243.6714 - val_accuracy: 0.7347\n",
            "Epoch 30/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00030: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6.5612 - accuracy: 0.9637 - val_loss: 312.0760 - val_accuracy: 0.7755\n",
            "Epoch 31/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 57.6023 - accuracy: 0.9000\n",
            "Epoch 00031: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 32.3638 - accuracy: 0.9585 - val_loss: 167.4401 - val_accuracy: 0.8163\n",
            "Epoch 32/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00032: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6.4246 - accuracy: 0.9637 - val_loss: 303.3604 - val_accuracy: 0.7755\n",
            "Epoch 33/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00033: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 20.4762 - accuracy: 0.9378 - val_loss: 178.9465 - val_accuracy: 0.7755\n",
            "Epoch 34/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00034: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 13.7827 - accuracy: 0.9637 - val_loss: 353.4270 - val_accuracy: 0.7347\n",
            "Epoch 35/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 2.3406 - accuracy: 0.9000\n",
            "Epoch 00035: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 18.6446 - accuracy: 0.9637 - val_loss: 183.3456 - val_accuracy: 0.7551\n",
            "Epoch 36/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 124.9532 - accuracy: 0.8000\n",
            "Epoch 00036: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 12.0250 - accuracy: 0.9585 - val_loss: 160.9981 - val_accuracy: 0.7959\n",
            "Epoch 37/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00037: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 14.0109 - accuracy: 0.9534 - val_loss: 173.8764 - val_accuracy: 0.8163\n",
            "Epoch 38/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00038: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 5.0733 - accuracy: 0.9482 - val_loss: 184.0087 - val_accuracy: 0.7143\n",
            "Epoch 39/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00039: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.8396 - accuracy: 0.9637 - val_loss: 159.8565 - val_accuracy: 0.7551\n",
            "Epoch 40/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 1.8707 - accuracy: 0.9000\n",
            "Epoch 00040: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 5.1465 - accuracy: 0.9793 - val_loss: 174.4748 - val_accuracy: 0.7755\n",
            "Epoch 41/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00041: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6.6346 - accuracy: 0.9689 - val_loss: 190.8524 - val_accuracy: 0.7755\n",
            "Epoch 42/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 27.5961 - accuracy: 0.9000\n",
            "Epoch 00042: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 5.2696 - accuracy: 0.9689 - val_loss: 178.5582 - val_accuracy: 0.8163\n",
            "Epoch 43/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.2044 - accuracy: 0.9000\n",
            "Epoch 00043: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 3.8600 - accuracy: 0.9637 - val_loss: 171.4043 - val_accuracy: 0.7959\n",
            "Epoch 44/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00044: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7375 - accuracy: 0.9896 - val_loss: 196.6276 - val_accuracy: 0.7551\n",
            "Epoch 45/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 2.7658e-05 - accuracy: 1.0000\n",
            "Epoch 00045: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 4.7793 - accuracy: 0.9689 - val_loss: 173.4786 - val_accuracy: 0.7755\n",
            "Epoch 46/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 9.3223 - accuracy: 0.9000\n",
            "Epoch 00046: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 3.3440 - accuracy: 0.9741 - val_loss: 172.5166 - val_accuracy: 0.8163\n",
            "Epoch 47/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 3.7549 - accuracy: 0.9000\n",
            "Epoch 00047: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 3.7858 - accuracy: 0.9637 - val_loss: 318.0837 - val_accuracy: 0.7347\n",
            "Epoch 48/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 2.4542 - accuracy: 0.9000\n",
            "Epoch 00048: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 15.0255 - accuracy: 0.9585 - val_loss: 185.6838 - val_accuracy: 0.7143\n",
            "Epoch 49/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 12.5765 - accuracy: 0.9000\n",
            "Epoch 00049: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 13.7986 - accuracy: 0.9741 - val_loss: 170.8121 - val_accuracy: 0.7959\n",
            "Epoch 50/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 5.0588e-36 - accuracy: 1.0000\n",
            "Epoch 00050: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.7629 - accuracy: 0.9793 - val_loss: 196.5229 - val_accuracy: 0.7959\n",
            "Epoch 51/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00051: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2786 - accuracy: 0.9896 - val_loss: 184.6960 - val_accuracy: 0.7551\n",
            "Epoch 52/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00052: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.9029 - accuracy: 0.9793 - val_loss: 251.0046 - val_accuracy: 0.7551\n",
            "Epoch 53/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 9.3510e-21 - accuracy: 1.0000\n",
            "Epoch 00053: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.7643 - accuracy: 0.9896 - val_loss: 230.5357 - val_accuracy: 0.7959\n",
            "Epoch 54/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00054: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 0.9948 - val_loss: 220.2922 - val_accuracy: 0.7755\n",
            "Epoch 55/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00055: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.8690 - accuracy: 0.9896 - val_loss: 223.8002 - val_accuracy: 0.7755\n",
            "Epoch 56/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00056: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.9948 - val_loss: 249.8179 - val_accuracy: 0.7755\n",
            "Epoch 57/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00057: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.9896 - val_loss: 256.9182 - val_accuracy: 0.7755\n",
            "Epoch 58/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00058: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.6373 - accuracy: 0.9948 - val_loss: 220.1745 - val_accuracy: 0.7959\n",
            "Epoch 59/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00059: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.6558 - accuracy: 0.9793 - val_loss: 192.7887 - val_accuracy: 0.7347\n",
            "Epoch 60/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00060: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 14.3241 - accuracy: 0.9896 - val_loss: 206.8419 - val_accuracy: 0.7755\n",
            "Epoch 61/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00061: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 3.6959 - accuracy: 0.9637 - val_loss: 194.3057 - val_accuracy: 0.7551\n",
            "Epoch 62/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 1.2873 - accuracy: 0.9000\n",
            "Epoch 00062: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.2844 - accuracy: 0.9585 - val_loss: 232.9709 - val_accuracy: 0.7347\n",
            "Epoch 63/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 2.9340e-20 - accuracy: 1.0000\n",
            "Epoch 00063: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.9896 - val_loss: 199.3899 - val_accuracy: 0.7755\n",
            "Epoch 64/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 5.2108 - accuracy: 0.9000\n",
            "Epoch 00064: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.3987 - accuracy: 0.9741 - val_loss: 217.3646 - val_accuracy: 0.7551\n",
            "Epoch 65/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 1.3368e-17 - accuracy: 1.0000\n",
            "Epoch 00065: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 21.3069 - accuracy: 0.9689 - val_loss: 284.6708 - val_accuracy: 0.6939\n",
            "Epoch 66/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00066: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.4865 - accuracy: 0.9845 - val_loss: 234.4673 - val_accuracy: 0.7551\n",
            "Epoch 67/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 2.7951 - accuracy: 0.9000\n",
            "Epoch 00067: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.9730 - accuracy: 0.9741 - val_loss: 180.4566 - val_accuracy: 0.7551\n",
            "Epoch 68/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 5.2358 - accuracy: 0.9000\n",
            "Epoch 00068: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.2360 - accuracy: 0.9741 - val_loss: 158.7657 - val_accuracy: 0.7551\n",
            "Epoch 69/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00069: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2395 - accuracy: 0.9845 - val_loss: 178.1520 - val_accuracy: 0.7755\n",
            "Epoch 70/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 2.5758e-32 - accuracy: 1.0000\n",
            "Epoch 00070: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9948 - val_loss: 173.4986 - val_accuracy: 0.7551\n",
            "Epoch 71/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 3.0960e-35 - accuracy: 1.0000\n",
            "Epoch 00071: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.2408 - accuracy: 0.9896 - val_loss: 303.2405 - val_accuracy: 0.7143\n",
            "Epoch 72/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 58.6059 - accuracy: 0.9000\n",
            "Epoch 00072: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 28.8193 - accuracy: 0.9741 - val_loss: 149.4158 - val_accuracy: 0.7551\n",
            "Epoch 73/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00073: val_loss did not improve from 128.80121\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 10.5854 - accuracy: 0.9430 - val_loss: 329.6094 - val_accuracy: 0.7347\n",
            "Epoch 74/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00074: val_loss improved from 128.80121 to 122.38660, saving model to .mdl_wts.hdf5\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 15.0446 - accuracy: 0.9896 - val_loss: 122.3866 - val_accuracy: 0.7959\n",
            "Epoch 75/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 15.3321 - accuracy: 0.8000\n",
            "Epoch 00075: val_loss did not improve from 122.38660\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 3.7615 - accuracy: 0.9637 - val_loss: 135.3056 - val_accuracy: 0.7755\n",
            "Epoch 76/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00076: val_loss improved from 122.38660 to 119.82411, saving model to .mdl_wts.hdf5\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 2.0618 - accuracy: 0.9793 - val_loss: 119.8241 - val_accuracy: 0.7755\n",
            "Epoch 77/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 1.5715e-14 - accuracy: 1.0000\n",
            "Epoch 00077: val_loss improved from 119.82411 to 108.99200, saving model to .mdl_wts.hdf5\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7163 - accuracy: 0.9741 - val_loss: 108.9920 - val_accuracy: 0.8163\n",
            "Epoch 78/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 1.3843 - accuracy: 0.9000\n",
            "Epoch 00078: val_loss did not improve from 108.99200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.4887 - accuracy: 0.9741 - val_loss: 121.3953 - val_accuracy: 0.7551\n",
            "Epoch 79/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00079: val_loss did not improve from 108.99200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 23.5622 - accuracy: 0.9689 - val_loss: 122.3458 - val_accuracy: 0.7347\n",
            "Epoch 80/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00080: val_loss did not improve from 108.99200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 69.4058 - accuracy: 0.9067 - val_loss: 405.9360 - val_accuracy: 0.6735\n",
            "Epoch 81/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 193.4822 - accuracy: 0.8000\n",
            "Epoch 00081: val_loss did not improve from 108.99200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 44.3515 - accuracy: 0.8860 - val_loss: 202.3031 - val_accuracy: 0.7347\n",
            "Epoch 82/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00082: val_loss did not improve from 108.99200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 5.8489 - accuracy: 0.9637 - val_loss: 138.7785 - val_accuracy: 0.8163\n",
            "Epoch 83/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 6.1915 - accuracy: 0.9000\n",
            "Epoch 00083: val_loss did not improve from 108.99200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 3.5729 - accuracy: 0.9689 - val_loss: 153.4984 - val_accuracy: 0.7755\n",
            "Epoch 84/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00084: val_loss did not improve from 108.99200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.6564 - accuracy: 0.9845 - val_loss: 124.7343 - val_accuracy: 0.7551\n",
            "Epoch 85/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00085: val_loss did not improve from 108.99200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.9406 - accuracy: 0.9637 - val_loss: 139.0298 - val_accuracy: 0.7551\n",
            "Epoch 86/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 6.6546 - accuracy: 0.9000\n",
            "Epoch 00086: val_loss did not improve from 108.99200\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.0033 - accuracy: 0.9793 - val_loss: 136.6671 - val_accuracy: 0.7551\n",
            "Epoch 87/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00087: val_loss improved from 108.99200 to 107.48786, saving model to .mdl_wts.hdf5\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 2.0266 - accuracy: 0.9896 - val_loss: 107.4879 - val_accuracy: 0.7959\n",
            "Epoch 88/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 1.7951e-27 - accuracy: 1.0000\n",
            "Epoch 00088: val_loss did not improve from 107.48786\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.3698 - accuracy: 0.9793 - val_loss: 108.6658 - val_accuracy: 0.7755\n",
            "Epoch 89/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 1.5240e-06 - accuracy: 1.0000\n",
            "Epoch 00089: val_loss improved from 107.48786 to 95.75791, saving model to .mdl_wts.hdf5\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.6405 - accuracy: 0.9896 - val_loss: 95.7579 - val_accuracy: 0.8163\n",
            "Epoch 90/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00090: val_loss did not improve from 95.75791\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.9741 - val_loss: 103.6807 - val_accuracy: 0.8571\n",
            "Epoch 91/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00091: val_loss did not improve from 95.75791\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 8.4510 - accuracy: 0.9741 - val_loss: 129.9755 - val_accuracy: 0.7959\n",
            "Epoch 92/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00092: val_loss did not improve from 95.75791\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 8.7154 - accuracy: 0.9585 - val_loss: 103.0698 - val_accuracy: 0.8163\n",
            "Epoch 93/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00093: val_loss did not improve from 95.75791\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.2485 - accuracy: 0.9793 - val_loss: 99.8439 - val_accuracy: 0.7959\n",
            "Epoch 94/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00094: val_loss did not improve from 95.75791\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 1.1561 - accuracy: 0.9793 - val_loss: 129.7334 - val_accuracy: 0.7959\n",
            "Epoch 95/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 1.2984e-34 - accuracy: 1.0000\n",
            "Epoch 00095: val_loss did not improve from 95.75791\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 9.3283 - accuracy: 0.9845 - val_loss: 119.5429 - val_accuracy: 0.7755\n",
            "Epoch 96/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 1.0971e-31 - accuracy: 1.0000\n",
            "Epoch 00096: val_loss did not improve from 95.75791\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 5.6041 - accuracy: 0.9689 - val_loss: 141.3512 - val_accuracy: 0.7347\n",
            "Epoch 97/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 2.5467 - accuracy: 0.9000\n",
            "Epoch 00097: val_loss did not improve from 95.75791\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 3.2569 - accuracy: 0.9585 - val_loss: 111.4919 - val_accuracy: 0.7551\n",
            "Epoch 98/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00098: val_loss did not improve from 95.75791\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 2.5424 - accuracy: 0.9689 - val_loss: 97.5031 - val_accuracy: 0.7143\n",
            "Epoch 99/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 5.9604e-09 - accuracy: 1.0000\n",
            "Epoch 00099: val_loss did not improve from 95.75791\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.9424 - accuracy: 0.9741 - val_loss: 113.4953 - val_accuracy: 0.7347\n",
            "Epoch 100/100\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00100: val_loss did not improve from 95.75791\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.9793 - val_loss: 115.4266 - val_accuracy: 0.7551\n",
            "\n",
            "\n",
            "CNN\n",
            "Epoch 1/100\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 293.8318 - accuracy: 0.4404 - val_loss: 165.5718 - val_accuracy: 0.5102\n",
            "Epoch 2/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 90.6826 - accuracy: 0.5648 - val_loss: 44.6307 - val_accuracy: 0.4490\n",
            "Epoch 3/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 63.1560 - accuracy: 0.6166 - val_loss: 40.8403 - val_accuracy: 0.5510\n",
            "Epoch 4/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 33.3507 - accuracy: 0.6477 - val_loss: 56.2953 - val_accuracy: 0.4898\n",
            "Epoch 5/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 29.5050 - accuracy: 0.7098 - val_loss: 53.3845 - val_accuracy: 0.4082\n",
            "Epoch 6/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 20.6429 - accuracy: 0.6528 - val_loss: 76.4592 - val_accuracy: 0.5306\n",
            "Epoch 7/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 24.0649 - accuracy: 0.6736 - val_loss: 42.8230 - val_accuracy: 0.5510\n",
            "Epoch 8/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 20.1427 - accuracy: 0.7150 - val_loss: 35.1019 - val_accuracy: 0.4694\n",
            "Epoch 9/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.3225 - accuracy: 0.7979 - val_loss: 35.0469 - val_accuracy: 0.4490\n",
            "Epoch 10/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 20.9423 - accuracy: 0.7513 - val_loss: 51.9030 - val_accuracy: 0.4694\n",
            "Epoch 11/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 20.4631 - accuracy: 0.7098 - val_loss: 20.6990 - val_accuracy: 0.5510\n",
            "Epoch 12/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.7729 - accuracy: 0.8342 - val_loss: 24.7469 - val_accuracy: 0.4898\n",
            "Epoch 13/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 9.9912 - accuracy: 0.8238 - val_loss: 27.2800 - val_accuracy: 0.3878\n",
            "Epoch 14/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.6748 - accuracy: 0.7772 - val_loss: 20.0258 - val_accuracy: 0.4694\n",
            "Epoch 15/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.1797 - accuracy: 0.7927 - val_loss: 19.7251 - val_accuracy: 0.4898\n",
            "Epoch 16/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.1070 - accuracy: 0.7824 - val_loss: 17.3683 - val_accuracy: 0.4694\n",
            "Epoch 17/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.9521 - accuracy: 0.7824 - val_loss: 12.7786 - val_accuracy: 0.4694\n",
            "Epoch 18/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.5158 - accuracy: 0.8290 - val_loss: 15.3136 - val_accuracy: 0.5306\n",
            "Epoch 19/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.3881 - accuracy: 0.8342 - val_loss: 16.8716 - val_accuracy: 0.5102\n",
            "Epoch 20/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.4318 - accuracy: 0.8808 - val_loss: 18.5903 - val_accuracy: 0.4694\n",
            "Epoch 21/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.9699 - accuracy: 0.8446 - val_loss: 14.5946 - val_accuracy: 0.4694\n",
            "Epoch 22/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0371 - accuracy: 0.8912 - val_loss: 16.7661 - val_accuracy: 0.4490\n",
            "Epoch 23/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.8973 - accuracy: 0.8342 - val_loss: 16.8473 - val_accuracy: 0.4898\n",
            "Epoch 24/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8726 - accuracy: 0.9067 - val_loss: 11.5825 - val_accuracy: 0.4694\n",
            "Epoch 25/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.0908 - accuracy: 0.8290 - val_loss: 19.2501 - val_accuracy: 0.4898\n",
            "Epoch 26/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.4046 - accuracy: 0.8756 - val_loss: 15.6532 - val_accuracy: 0.3469\n",
            "Epoch 27/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0387 - accuracy: 0.9016 - val_loss: 19.0455 - val_accuracy: 0.5102\n",
            "Epoch 28/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.4224 - accuracy: 0.9430 - val_loss: 13.9493 - val_accuracy: 0.4490\n",
            "Epoch 29/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0821 - accuracy: 0.9689 - val_loss: 14.6474 - val_accuracy: 0.4490\n",
            "Epoch 30/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0999 - accuracy: 0.9793 - val_loss: 16.3655 - val_accuracy: 0.4694\n",
            "Epoch 31/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.2194 - accuracy: 0.9637 - val_loss: 17.6892 - val_accuracy: 0.4490\n",
            "Epoch 32/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.2039 - accuracy: 0.8964 - val_loss: 26.0716 - val_accuracy: 0.4898\n",
            "Epoch 33/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9300 - accuracy: 0.9171 - val_loss: 15.3774 - val_accuracy: 0.4286\n",
            "Epoch 34/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.2869 - accuracy: 0.9430 - val_loss: 15.7098 - val_accuracy: 0.4898\n",
            "Epoch 35/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9741 - val_loss: 14.2225 - val_accuracy: 0.4898\n",
            "Epoch 36/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0961 - accuracy: 0.9741 - val_loss: 16.5637 - val_accuracy: 0.4082\n",
            "Epoch 37/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.7258 - accuracy: 0.9223 - val_loss: 20.5762 - val_accuracy: 0.5102\n",
            "Epoch 38/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.1584 - accuracy: 0.9585 - val_loss: 17.6612 - val_accuracy: 0.4694\n",
            "Epoch 39/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.1385 - accuracy: 0.9689 - val_loss: 22.9413 - val_accuracy: 0.5102\n",
            "Epoch 40/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8975 - accuracy: 0.9430 - val_loss: 15.8065 - val_accuracy: 0.4898\n",
            "Epoch 41/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.1680 - accuracy: 0.9689 - val_loss: 16.0226 - val_accuracy: 0.5306\n",
            "Epoch 42/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0399 - accuracy: 0.9793 - val_loss: 14.4034 - val_accuracy: 0.5102\n",
            "Epoch 43/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0701 - accuracy: 0.9793 - val_loss: 13.6020 - val_accuracy: 0.4490\n",
            "Epoch 44/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0554 - accuracy: 0.9275 - val_loss: 11.6527 - val_accuracy: 0.4694\n",
            "Epoch 45/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8468 - accuracy: 0.9119 - val_loss: 17.4567 - val_accuracy: 0.5102\n",
            "Epoch 46/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.4044 - accuracy: 0.9585 - val_loss: 21.3202 - val_accuracy: 0.4490\n",
            "Epoch 47/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.8413 - accuracy: 0.8342 - val_loss: 10.0243 - val_accuracy: 0.5102\n",
            "Epoch 48/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.0609 - accuracy: 0.8135 - val_loss: 9.9022 - val_accuracy: 0.4490\n",
            "Epoch 49/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.6883 - accuracy: 0.8808 - val_loss: 6.9258 - val_accuracy: 0.5510\n",
            "Epoch 50/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.7630 - accuracy: 0.9171 - val_loss: 11.9962 - val_accuracy: 0.4490\n",
            "Epoch 51/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.5740 - accuracy: 0.9067 - val_loss: 9.8574 - val_accuracy: 0.5306\n",
            "Epoch 52/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.4067 - accuracy: 0.8860 - val_loss: 9.3052 - val_accuracy: 0.4898\n",
            "Epoch 53/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9267 - accuracy: 0.8705 - val_loss: 10.4084 - val_accuracy: 0.5102\n",
            "Epoch 54/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.3110 - accuracy: 0.9326 - val_loss: 7.0555 - val_accuracy: 0.5510\n",
            "Epoch 55/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.4038 - accuracy: 0.9534 - val_loss: 6.9823 - val_accuracy: 0.5306\n",
            "Epoch 56/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.6592 - accuracy: 0.9119 - val_loss: 6.8817 - val_accuracy: 0.5306\n",
            "Epoch 57/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8148 - accuracy: 0.8705 - val_loss: 13.0859 - val_accuracy: 0.5102\n",
            "Epoch 58/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0164 - accuracy: 0.8705 - val_loss: 10.9696 - val_accuracy: 0.4286\n",
            "Epoch 59/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.9326 - val_loss: 12.8164 - val_accuracy: 0.4490\n",
            "Epoch 60/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8812 - accuracy: 0.9223 - val_loss: 11.2424 - val_accuracy: 0.5102\n",
            "Epoch 61/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.7892 - accuracy: 0.8705 - val_loss: 15.3346 - val_accuracy: 0.4286\n",
            "Epoch 62/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.3559 - accuracy: 0.9378 - val_loss: 9.5045 - val_accuracy: 0.4898\n",
            "Epoch 63/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.1461 - accuracy: 0.9585 - val_loss: 10.2908 - val_accuracy: 0.4898\n",
            "Epoch 64/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0770 - accuracy: 0.9741 - val_loss: 7.7409 - val_accuracy: 0.5306\n",
            "Epoch 65/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0200 - accuracy: 0.9896 - val_loss: 9.7228 - val_accuracy: 0.4286\n",
            "Epoch 66/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0090 - accuracy: 0.9948 - val_loss: 10.5233 - val_accuracy: 0.4694\n",
            "Epoch 67/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.7230e-04 - accuracy: 1.0000 - val_loss: 10.5014 - val_accuracy: 0.4694\n",
            "Epoch 68/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.2994e-04 - accuracy: 1.0000 - val_loss: 10.6012 - val_accuracy: 0.4694\n",
            "Epoch 69/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.6268e-04 - accuracy: 1.0000 - val_loss: 10.6353 - val_accuracy: 0.4694\n",
            "Epoch 70/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.3065e-04 - accuracy: 1.0000 - val_loss: 10.6609 - val_accuracy: 0.4694\n",
            "Epoch 71/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.0282e-04 - accuracy: 1.0000 - val_loss: 10.7177 - val_accuracy: 0.4694\n",
            "Epoch 72/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.8489e-04 - accuracy: 1.0000 - val_loss: 10.7398 - val_accuracy: 0.4694\n",
            "Epoch 73/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.6967e-04 - accuracy: 1.0000 - val_loss: 10.7798 - val_accuracy: 0.4694\n",
            "Epoch 74/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.5805e-04 - accuracy: 1.0000 - val_loss: 10.7964 - val_accuracy: 0.4694\n",
            "Epoch 75/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.4857e-04 - accuracy: 1.0000 - val_loss: 10.8356 - val_accuracy: 0.4694\n",
            "Epoch 76/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.3940e-04 - accuracy: 1.0000 - val_loss: 10.8522 - val_accuracy: 0.4694\n",
            "Epoch 77/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.3189e-04 - accuracy: 1.0000 - val_loss: 10.8702 - val_accuracy: 0.4694\n",
            "Epoch 78/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.2582e-04 - accuracy: 1.0000 - val_loss: 10.8987 - val_accuracy: 0.4694\n",
            "Epoch 79/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1972e-04 - accuracy: 1.0000 - val_loss: 10.9124 - val_accuracy: 0.4694\n",
            "Epoch 80/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1344e-04 - accuracy: 1.0000 - val_loss: 10.9374 - val_accuracy: 0.4694\n",
            "Epoch 81/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0857e-04 - accuracy: 1.0000 - val_loss: 10.9511 - val_accuracy: 0.4694\n",
            "Epoch 82/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0415e-04 - accuracy: 1.0000 - val_loss: 10.9831 - val_accuracy: 0.4694\n",
            "Epoch 83/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 9.9631e-05 - accuracy: 1.0000 - val_loss: 10.9968 - val_accuracy: 0.4694\n",
            "Epoch 84/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 9.6312e-05 - accuracy: 1.0000 - val_loss: 11.0030 - val_accuracy: 0.4694\n",
            "Epoch 85/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 9.3118e-05 - accuracy: 1.0000 - val_loss: 11.0198 - val_accuracy: 0.4694\n",
            "Epoch 86/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 9.0097e-05 - accuracy: 1.0000 - val_loss: 11.0378 - val_accuracy: 0.4694\n",
            "Epoch 87/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 8.7085e-05 - accuracy: 1.0000 - val_loss: 11.0469 - val_accuracy: 0.4694\n",
            "Epoch 88/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 8.4971e-05 - accuracy: 1.0000 - val_loss: 11.0533 - val_accuracy: 0.4694\n",
            "Epoch 89/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 8.2803e-05 - accuracy: 1.0000 - val_loss: 11.0787 - val_accuracy: 0.4694\n",
            "Epoch 90/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 7.9569e-05 - accuracy: 1.0000 - val_loss: 11.0702 - val_accuracy: 0.4694\n",
            "Epoch 91/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 7.7295e-05 - accuracy: 1.0000 - val_loss: 11.0964 - val_accuracy: 0.4694\n",
            "Epoch 92/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 7.5066e-05 - accuracy: 1.0000 - val_loss: 11.1120 - val_accuracy: 0.4694\n",
            "Epoch 93/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 7.2997e-05 - accuracy: 1.0000 - val_loss: 11.1272 - val_accuracy: 0.4694\n",
            "Epoch 94/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 7.1147e-05 - accuracy: 1.0000 - val_loss: 11.1353 - val_accuracy: 0.4694\n",
            "Epoch 95/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.9403e-05 - accuracy: 1.0000 - val_loss: 11.1358 - val_accuracy: 0.4694\n",
            "Epoch 96/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.7622e-05 - accuracy: 1.0000 - val_loss: 11.1636 - val_accuracy: 0.4694\n",
            "Epoch 97/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.6782e-05 - accuracy: 1.0000 - val_loss: 11.1792 - val_accuracy: 0.4694\n",
            "Epoch 98/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.4552e-05 - accuracy: 1.0000 - val_loss: 11.1755 - val_accuracy: 0.4694\n",
            "Epoch 99/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.2911e-05 - accuracy: 1.0000 - val_loss: 11.1842 - val_accuracy: 0.4694\n",
            "Epoch 100/100\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.1957e-05 - accuracy: 1.0000 - val_loss: 11.1959 - val_accuracy: 0.4694\n",
            "Accuracy: 46.94\n",
            "mathews coefficient -0.024441185836892216\n",
            "confusion matrix [[13  8]\n",
            " [18 10]]\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.95805, saving model to .mdl_wts.hdf5\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.95805 to 0.80754, saving model to .mdl_wts.hdf5\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.80754\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.80754 to 0.75326, saving model to .mdl_wts.hdf5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.75326 to 0.70216, saving model to .mdl_wts.hdf5\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.70216\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.70216 to 0.69530, saving model to .mdl_wts.hdf5\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.69530\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.69530\n",
            "LSTM\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Accuracy: 51.02\n",
            "mathews coefficient 0.1414213562373095\n",
            "confusion matrix [[ 1 24]\n",
            " [ 0 24]]\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Accuracy: 51.02\n",
            "mathews coefficient 0.0\n",
            "confusion matrix [[ 0 24]\n",
            " [ 0 25]]\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Accuracy: 45.83\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3970e77b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "mathews coefficient -0.12598815766974242\n",
            "confusion matrix [[20  4]\n",
            " [22  2]]\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Accuracy: 47.92\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff395a1cae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "mathews coefficient -0.14586499149789456\n",
            "confusion matrix [[ 0 24]\n",
            " [ 1 23]]\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Accuracy: 47.92\n",
            "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff393b7a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "mathews coefficient -0.06819943394704735\n",
            "confusion matrix [[21  3]\n",
            " [22  2]]\n",
            "48.74% (+/-2.01%)\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.4930 - accuracy: 0.5413\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}