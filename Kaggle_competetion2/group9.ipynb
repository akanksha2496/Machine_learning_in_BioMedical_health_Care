{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Group-9_PriyankaBoral_MT19127.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKoCrTFFsN_Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKoSNvwNsN8d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqJxhrz1sN5a"
      },
      "source": [
        " import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "6wDBCt0esN1_",
        "outputId": "0a78b067-022d-4961-909c-5b0c8f287bcc"
      },
      "source": [
        "input1 = sys.argv[1]#kaggle_train.csv\n",
        "input2= sys.argv[2]#kaggle_test.csv\n",
        "output1 = sys.argv[3]#sample.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b67485e46322>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#kaggle_train.csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#kaggle_test.csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moutput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#sample.csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxjrMDJX3HPA"
      },
      "source": [
        "## Sequential model with dense layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYqeD2jgxcpw"
      },
      "source": [
        "print(\"Sequential model with dense layer\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzHN0G5zU_DY"
      },
      "source": [
        "import pandas as pd\n",
        "#reading the training csv file using pandas\n",
        "df_train = pd.read_csv(input1)\n",
        "#reading the testing csv file using pandas\n",
        "df_test = pd.read_csv(input2)\n",
        "#assigning the train labels in a variable\n",
        "target=df_train['Labels']\n",
        "#dropping the labels fron input data\n",
        "df_train.drop(['Labels'], inplace = True,axis=1) \n",
        "#droppung the ID from input data as it has no use\n",
        "df_train.drop(['ID'], inplace = True,axis=1)\n",
        "#assigning the testing ID in a variable\n",
        "test_labels=df_test['ID']\n",
        "#dropping the test ID from data\n",
        "df_test.drop(['ID'], inplace = True,axis=1)\n",
        "#splitting the data into test nad train part\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_train, target, test_size=0.20, random_state=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql3TXFi3-C2U"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "#dense layers are used with different nodes abd last layer is sigmoid for binary classification\n",
        "model = keras.Sequential([\n",
        "    #keras.layers.Dense(250,activation='relu',input_shape=(318,)),\n",
        "    #keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(150,activation='relu'),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Dense(1,activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY2dKwHk-f1-"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "#Adam is used as optimiser and binary cross entropy loss\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "#checkpoint is made for checking decrease in  validation loss \n",
        "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min',verbose=1)\n",
        "#model is run on batch size 10 and 100 epoch\n",
        "model.fit(X_train.values,np.asarray(y_train), epochs=100,validation_split=0.2,callbacks=[mcp_save],batch_size=10,verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO1Yoyn9qtsH"
      },
      "source": [
        "#checking the accuracy on validation data \n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Accuracy: %.2f' % (scores[1]*100))\n",
        "#predicting on testind data\n",
        "y_pred=model.predict_classes(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAf_TboCB40E"
      },
      "source": [
        "#MCC score on validation data\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "print(\"MCC at Sequential: \",matthews_corrcoef(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCAcMSkNxa9i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zsgpo-m18kR"
      },
      "source": [
        "#fitting the model on whole train data\n",
        "model.fit(df_train.values,np.asarray(target), epochs=100,validation_split=0.2,callbacks=[mcp_save],batch_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXyCfP-a2Dhp"
      },
      "source": [
        "#predicting on kaggle test data\n",
        "y_pred=model.predict_classes(df_test)\n",
        "result=[]\n",
        "for i in y_pred:\n",
        "  result.append(i[0])\n",
        "#writing tthe output on a dataframe\n",
        "data_res=pd.DataFrame()\n",
        "data_res['ID']=test_labels\n",
        "data_res['Labels']=result\n",
        "#writing the dataframe on csv file\n",
        "data_res.to_csv (r'dense(150,0.1,1).csv', index = False,header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAhcavYKsuvm"
      },
      "source": [
        "data_res.to_csv(output1,index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2P70lysXhr1"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkHk2Yl6yJsS"
      },
      "source": [
        "print(\"\\n\")\n",
        "print(\"CNN\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mEh3Zi9uKRq"
      },
      "source": [
        "import pandas as pd\n",
        "#reading the training csv file using pandas\n",
        "df_train = pd.read_csv(input1)\n",
        "#reading the testing csv file using pandas\n",
        "df_test = pd.read_csv(input2)\n",
        "#assigning the train labels in a variable\n",
        "target=df_train['Labels']\n",
        "#dropping the labels fron input data\n",
        "df_train.drop(['Labels'], inplace = True,axis=1) \n",
        "#droppung the ID from input data as it has no use\n",
        "df_train.drop(['ID'], inplace = True,axis=1)\n",
        "#assigning the testing ID in a variable\n",
        "test_labels=df_test['ID']\n",
        "#dropping the test ID from data\n",
        "df_test.drop(['ID'], inplace = True,axis=1)\n",
        "#splitting the data into test nad train part\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_train, target, test_size=0.20, random_state=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDA2qiP44fbJ"
      },
      "source": [
        "import numpy as np\n",
        "#changing the dimension for fitting in CNN model\n",
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCmCKix0rT7P"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, Flatten\n",
        "#create model\n",
        "model = Sequential()\n",
        "#add model layers\n",
        "model.add(Conv1D(64, kernel_size=5, activation='relu', input_shape=(318,1)))\n",
        "model.add(Conv1D(30, kernel_size=5, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N44ceh3xsTYm"
      },
      "source": [
        "#compile model using accuracy to measure model performance\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zwx-p3ZsX_6"
      },
      "source": [
        "#train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,batch_size=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omHUMOdOIEvW"
      },
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Accuracy: %.2f' % (scores[1]*100))\n",
        "y_pred=model.predict_classes(X_test)\n",
        "from sklearn.metrics import matthews_corrcoef,confusion_matrix\n",
        "print(\"mathews coefficient\",matthews_corrcoef(y_test, y_pred))\n",
        "print(\"confusion matrix\",confusion_matrix(y_test, y_pred))\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxIu0246o1WU"
      },
      "source": [
        "df_train = np.expand_dims(df_train, axis=2)\n",
        "df_test = np.expand_dims(df_test, axis=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DzGYX3upR1i"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min',verbose=1)\n",
        "model.fit(df_train,np.asarray(target), epochs=100,validation_split=0.2,callbacks=[mcp_save],batch_size=5,verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rvVwpsSoxDm"
      },
      "source": [
        "#predicting on kaggle test data\n",
        "y_pred=model.predict_classes(df_test)\n",
        "result=[]\n",
        "for i in y_pred:\n",
        "  result.append(i[0])\n",
        "#writing tthe output on a dataframe\n",
        "data_res=pd.DataFrame()\n",
        "data_res['ID']=test_labels\n",
        "data_res['Labels']=result\n",
        "#writing the dataframe on csv file\n",
        "data_res.to_csv (r'dense(150,0.1,1).csv', index = False,header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed_geC2ws04C"
      },
      "source": [
        "data_res.to_csv(output1,index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POude12YPfRa"
      },
      "source": [
        "# LSTM:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYEDqZoax3dv"
      },
      "source": [
        "print(\"LSTM\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCDum458Pw2B"
      },
      "source": [
        "**Import libearies that is panads and then read here the train file into the dataframe, and put in variable df:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0ueLyAuPXYP"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(input1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nhqcP_XPwCz"
      },
      "source": [
        "**Show the top rows of dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp0efcGdPc0U"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzV8NkIDP9EN"
      },
      "source": [
        "**Put the values of labele column in the target variable so can use furthur, and drop the 'Labels' column from the tarin data:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvuq-e4QPc2U"
      },
      "source": [
        "target=df['Labels']\n",
        "df.drop(['Labels'], inplace = True,axis=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU3CbivZQC-l"
      },
      "source": [
        "**Shape of train data is 242by319:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCqL12BGPc5L"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZQNqjTuQH7W"
      },
      "source": [
        "**Print the target values of all 242 rows:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0kq3Zw3Pc6p"
      },
      "source": [
        "target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHpqYwByQNa0"
      },
      "source": [
        "**this is dataframe with all columns and without taget columns:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2Lq0j1nPc97"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SGjCBk9QXTK"
      },
      "source": [
        "**removing the ID column from the train data as it is of not use right now we can use it furthur while generating target of sample output:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94RKnu4IQTQj"
      },
      "source": [
        "df.drop(['ID'], inplace = True,axis=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH3ZtdWjQcGi"
      },
      "source": [
        "**This is final dataset after removing ID and Label columns:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy55d-ZXQTN5"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSbvenn3QhMQ"
      },
      "source": [
        "**Here in test variable all the test data is assigned in the form of dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxiogpB2QTKe"
      },
      "source": [
        "test=pd.read_csv(input2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgpoAm21Qs8z"
      },
      "source": [
        "**Values of ID column were assigned into the test_labels variable so can use further while prediction:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWi3Xy4pQTI5"
      },
      "source": [
        "test_labels=test['ID']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e8O77rQQx01"
      },
      "source": [
        "**Here ID column is dropped from test data as currently it will not used while test labels predictions:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOlbAMUvQTFQ"
      },
      "source": [
        "test.drop(['ID'], inplace = True,axis=1) \n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag7SWdJzRXOl"
      },
      "source": [
        "**This is function for Matthews_correlation_coefficient on the basis of which we decide which model is best:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9RUZsGFRTCF"
      },
      "source": [
        "import math\n",
        "\n",
        "def Mattews_Correlation_Coefficient(tp,tn,fp,fn):\n",
        "  if (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)!=0:\n",
        "    MCC=((tp*tn)-(fp*fn))/((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))**(0.5)\n",
        "  else:\n",
        "    MCC=0\n",
        "  return MCC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OnTqg-gRcci"
      },
      "source": [
        "**From here LSTM is started to apply as a model into the train data. And here we tarin the model and check validation accuracy as well:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0P5A7_DRTEh"
      },
      "source": [
        "from keras.layers.recurrent import LSTM\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUthPz8ZRTG5"
      },
      "source": [
        "# load test data again and upload into the dataframe:\n",
        "test=pd.read_csv(input2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkEu1-j2RTJi"
      },
      "source": [
        "# drop ID column from the test data:\n",
        "test.drop(['ID'],inplace = True,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00CzVTaGRTLt"
      },
      "source": [
        "# convert test dataframe into the numpy array so can use furthur:\n",
        "test=np.asarray(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wikXhw2iRTOb"
      },
      "source": [
        "#define 5-fold cross validation\n",
        "kfold=StratifiedKFold(n_splits=5,shuffle=True, random_state=0)\n",
        "#kfold = KFold(n_splits=10)\n",
        "# reshaping of df that is train data and put it on X which is numpy array\n",
        "# And in X_reshape amd test_reshape we have store the shape which can use \n",
        "# furthur to reshape while training the model:\n",
        "X=np.asarray(df)\n",
        "X_reshape= np.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "test_reshape=np.reshape(test, (test.shape[0],1,test.shape[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVb7BzeKRTRb"
      },
      "source": [
        "# type of the  X:\n",
        "type(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSib6xirRxxE"
      },
      "source": [
        "# Shape of the X: train data:\n",
        "X.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On9dTi3Tv90-"
      },
      "source": [
        "y=np.asarray(target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX2URxr5R5Dm"
      },
      "source": [
        "**Here we train the model by applying LSTM where it have 2 hidden layer, of 200, 150, 16 and output is 2 by applying activation function relu relu and softmax for output.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZunaurfbRxzT"
      },
      "source": [
        "cvscores=[]\n",
        "i1=[]\n",
        "i=0\n",
        "for train,test in kfold.split(X,y):\n",
        "  i=i+1\n",
        "  model = Sequential()\n",
        "  model.add(LSTM((200),input_shape=(1,318),activation='relu',return_sequences=True))\n",
        "  # model.add(LSTM(150,activation='relu'))\n",
        "  model.add(LSTM(16,activation='relu'))\n",
        " \n",
        "  model.add(Dense(2,activation='softmax'))\n",
        " \n",
        "  i1.append(i)\n",
        "  #compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "  mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_acc', mode='max')\n",
        "  reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
        "  #train the model\n",
        "  history=model.fit(X_reshape[train], y[train], epochs=100,batch_size=5,callbacks=[earlyStopping,mcp_save],validation_data=(X_reshape[test],y[test]),verbose=0)\n",
        "\n",
        "  #Evaluate the model\n",
        "  scores = model.evaluate(X_reshape[test], y[test], verbose=0)\n",
        "  print('Accuracy: %.2f' % (scores[1]*100))\n",
        "  #MCC score on validation data\n",
        "  cvscores.append(scores[1]*100)\n",
        "  predicted_value=model.predict_classes(X_reshape[test])\n",
        "  from sklearn.metrics import matthews_corrcoef,confusion_matrix\n",
        "  print(\"mathews coefficient\",matthews_corrcoef(y[test], predicted_value))\n",
        "  print(\"confusion matrix\",confusion_matrix(y[test], predicted_value))\n",
        "  import warnings\n",
        "  warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "print(\"%.2f%% (+/-%.2f%%)\" % (np.mean(cvscores),np.std(cvscores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4pAQHVJSAQA"
      },
      "source": [
        "**fit the model by using train data and then predict the output of test data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrNXD0mSRx2M"
      },
      "source": [
        "model.fit(X_reshape, y)\n",
        "y_pred=model.predict_classes(test_reshape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI183EijSC60"
      },
      "source": [
        "**Here label encoding is done if value greater then or equal to 1 then say it as 1 else put it as 0:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJZNNzkURx4G"
      },
      "source": [
        "yp=[]\n",
        "for i in y_pred:\n",
        "  if i>=1:\n",
        "    yp.append(1)\n",
        "  else:\n",
        "    yp.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdpyH4-yxxbj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDX5n4MoxuHt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tkh8p40xSILy"
      },
      "source": [
        "**Here we generate sample.csv file so we can upload in kaggle to check the output:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuyYdUv-Rx7Y"
      },
      "source": [
        "data_res=pd.DataFrame()\n",
        "data_res['ID']=test_labels\n",
        "data_res['Lable']=yp\n",
        "data_res.to_csv (r'LSTM3_more1.csv', index = False,header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCQT6dqZq82W"
      },
      "source": [
        "data_res.to_csv(output1,index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Gzu2FvGymEQ"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwC_fDjnq_TL"
      },
      "source": [
        "# from sklearn.neural_network import MLPClassifier\n",
        "# clf = MLPClassifier(solver='adam', alpha=1e-5,\n",
        "#                    hidden_layer_sizes=(1,318), random_state=0)\n",
        "\n",
        "# #clf=MLPClassifier(hidden_layer_sizes=(15, ), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
        "\n",
        "\n",
        "# #clf=MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5,2), random_state=1,\n",
        "#                 #solver='lbfgs')\n",
        "\n",
        "# clf.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TiBT3I3rAdn"
      },
      "source": [
        "# from sklearn.model_selection import cross_val_score\n",
        "# cross_val_score(clf,X_train,y_train,cv=5).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OBay6eVrAfl"
      },
      "source": [
        "# #predicting on kaggle test data\n",
        "# y_pred=model.predict_classes(y_test)\n",
        "# result=[]\n",
        "# for i in y_pred:\n",
        "#   result.append(i[0])\n",
        "# #writing tthe output on a dataframe\n",
        "# data_res=pd.DataFrame()\n",
        "# data_res['ID']=test_labels\n",
        "# data_res['Labels']=result\n",
        "# #writing the dataframe on csv file\n",
        "# data_res.to_csv (r'mlp.csv', index = False,header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdnYZv_UrAjt"
      },
      "source": [
        "# from sklearn.metrics import matthews_corrcoef,confusion_matrix\n",
        "# print(\"mathews coefficient\",matthews_corrcoef(y_test, y_pred))\n",
        "# print(\"confusion matrix\",confusion_matrix(y_test, y_pred))\n",
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}